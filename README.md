# ğŸš¢ Titanic Survival Predictor

### Machine Learning Classification Project for Passenger Survival Prediction

**Binary Classification** Â· **Feature Engineering** Â· **Model Comparison** Â· **Hyperparameter Tuning** Â· **Streamlit Deployment**

Built using Python & Scikit-learn | End-to-End ML Pipeline

---

> **"Not all passengers had equal chances of survival."**  
> This project analyzes historical passenger data and builds a machine learning model to predict survival probability on the Titanic.

---

## ğŸ“‹ Table of Contents

- [The Challenge](#-the-challenge)
- [Exploratory Data Analysis](#-exploratory-data-analysis)
- [Feature Engineering](#-feature-engineering-approach)
- [Models Implemented](#-models-implemented)
- [Model Evaluation](#-model-evaluation--monitoring)
- [Feature Importance](#-feature-importance-insights)
- [Deployment](#-deployment)
- [Tech Stack](#-tech-stack)
- [Project Structure](#-repository-structure)
- [Run Locally](#-how-to-run-locally)
- [Key Learnings](#-key-learnings)
- [Author](#-author)

---

## ğŸ”´ The Challenge

The sinking of the Titanic remains one of the most famous maritime disasters in history.

Given passenger details such as:

- Age  
- Gender  
- Passenger Class  
- Fare  
- Family Members Aboard  
- Port of Embarkation  

The objective is to build a **supervised machine learning model** that predicts:

Did the passenger survive?  
0 â†’ Did Not Survive  
1 â†’ Survived  

This is a **binary classification problem**.

---

## ğŸ“Š Exploratory Data Analysis

Before modeling, extensive **Exploratory Data Analysis (EDA)** was performed to understand patterns and relationships.

### Analysis Performed

- Survival distribution analysis
- Gender vs survival comparison
- Passenger class survival trends
- Missing value inspection
- Feature correlation visualization

### ğŸ” Key Observations

- Female passengers had significantly higher survival rates.
- First-class passengers had higher survival probability.
- Higher ticket fares showed positive correlation with survival.
- Age and family size influenced survival probability.

---

## âš™ Feature Engineering Approach

Feature engineering significantly improved model performance.

### âœ… Handling Missing Values

| Feature | Strategy |
|---|---|
| Age | Filled using median grouped by passenger class |
| Embarked | Filled using mode |
| Cabin | Dropped due to excessive missing values |

---

### âœ… Feature Creation

#### 1ï¸âƒ£ FamilySize
FamilySize = SibSp + Parch + 1


- Captures family presence impact
- Improves prediction performance

#### 2ï¸âƒ£ Title Extraction

- Extracted titles (Mr, Mrs, Miss, etc.) from passenger names
- Rare titles grouped into **"Rare"**
- Improved demographic representation

---

### âœ… Encoding

- Label Encoding â†’ Sex
- One-Hot Encoding â†’ Embarked, Title

---

### âœ… Feature Scaling

StandardScaler applied to:

- Age  
- Fare  
- FamilySize  

Improves performance for linear and distance-based models.

---

## ğŸ¤– Models Implemented

The following machine learning models were trained and compared:

- Logistic Regression
- Decision Tree Classifier
- Random Forest Classifier
- Support Vector Machine (SVM)

### Hyperparameter Optimization

- GridSearchCV
- 5-Fold Cross Validation

---

## ğŸ“ˆ Model Evaluation & Monitoring

### Evaluation Metrics Used

- Accuracy
- Precision
- Recall
- F1-Score
- Confusion Matrix
- Cross-Validation Score

---

## ğŸ† Final Selected Model: Random Forest

The tuned Random Forest model achieved strong and balanced performance.

### Performance Characteristics

- High overall accuracy
- Balanced precision and recall
- Reduced overfitting through cross-validation
- Clear feature importance ranking

---

## ğŸ“Š Feature Importance Insights

Top influential features:

- Sex
- Passenger Class (Pclass)
- Fare
- Age
- FamilySize

These findings align with historical survival patterns.

---

## ğŸš€ Deployment

The trained model was serialized using:

- **pickle**

A web application was built using **Streamlit** to:

- Accept passenger input data
- Apply preprocessing pipeline
- Scale features
- Generate survival prediction
- Display user-friendly output

---

## ğŸ›  Tech Stack

| Layer | Technology |
|---|---|
| Programming | Python |
| Data Processing | Pandas, NumPy |
| Visualization | Matplotlib, Seaborn |
| Machine Learning | Scikit-learn |
| Deployment | Streamlit |
| Model Storage | Pickle |

---

## ğŸ“‚ Repository Structure
titanic-survival-predictor/
â”‚
â”œâ”€â”€ data/
â”œâ”€â”€ notebook/
â”‚ â””â”€â”€ titanic_survival_analysis.ipynb
â”œâ”€â”€ app.py
â”œâ”€â”€ titanic_model.pkl
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE

---

## â–¶ How to Run Locally

```bash
# Clone the repository
git clone https://github.com/EduLinkUp/titanic-survival-predictor.git

# Navigate to project folder
cd titanic-survival-predictor

# Install dependencies
pip install -r requirements.txt

# Run application
streamlit run app.py

---

### ğŸ¯ Key Learnings

- Feature engineering significantly improves model performance.
- Cross-validation helps prevent overfitting.
- Comparing multiple models improves decision confidence.
- Clean project structure enhances readability and usability.
- End-to-end ML pipelines include preprocessing â†’ training â†’ deployment.

---

### ğŸ‘©â€ğŸ’» Author

**Malleswarapu Sriya**  
Machine Learning Enthusiast | Data Science Student

---